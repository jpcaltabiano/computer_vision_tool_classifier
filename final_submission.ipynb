{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A script for data augmentation and formatting the data directory\n",
    "# for use with the following data loaders\n",
    "\n",
    "# Unzip kaggle data from https://www.kaggle.com/salmaneunus/mechanical-tools-dataset into a directory called 'data' and run this script from the parent directory\n",
    "# | computervision_final\n",
    "# | -> final_submission.ipynb\n",
    "# | -> data\n",
    "#    | -> Mechanical Tools\n",
    "#    | -> Annontated.csv\n",
    "#    | -> etc.\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "os.system('mv data old_data')\n",
    "os.system('mkdir data')\n",
    "os.system('cp -r old_data/Mechanical\\ Tools\\ Image\\ dataset/Mechanical\\ Tools\\ Image\\ dataset/Hammer old_data/Mechanical\\ Tools\\ Image\\ dataset/Mechanical\\ Tools\\ Image\\ dataset/Screw\\ Driver old_data/Mechanical\\ Tools\\ Image\\ dataset/Mechanical\\ Tools\\ Image\\ dataset/Wrench data')\n",
    "os.system('mv data/Hammer data/hammer')\n",
    "os.system('mv data/Screw\\ Driver data/screwdriver')\n",
    "os.system('mv data/Wrench data/wrench')\n",
    "\n",
    "count = 1\n",
    "for path in os.listdir(f'{cwd}/data'):\n",
    "    for file in os.listdir(f'{cwd}/data/{path}'):\n",
    "        os.rename(f'{cwd}/data/{path}/{file}', f'{cwd}/data/{path}/{path}_image_{count}.jpg')\n",
    "        count += 1\n",
    "    count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One method we used for loading data\n",
    "\n",
    "data_dir = pathlib.Path(f'{os.getcwd()}/data/train')\n",
    "batch_size = 32\n",
    "imgh = 120 # height\n",
    "imgw = 120 # width\n",
    "\n",
    "# training data\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir, validation_split=0.2, subset='training',seed=1,\n",
    "    image_size=(imgh, imgw),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# testing data\n",
    "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir, validation_split=0.2, subset='validation',seed=1,\n",
    "    image_size=(imgh, imgw),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "classes = train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying a sample of our training data\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i+10].numpy().astype(\"uint8\"))\n",
    "    plt.title(classes[labels[i+10]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our implementation of the Canny edge detector\n",
    "\n",
    "def auto_canny(image_a, sigma=0.33):\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image_a)\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "    # return the edged image\n",
    "    return edged\n",
    "\n",
    "\n",
    "W = 255\n",
    "i = 0\n",
    "for foldername in os.listdir(path):\n",
    "    for filename in os.listdir(path + '/' + foldername):\n",
    "        oriimg = Image.open(path + '/' + foldername + '/' + filename)\n",
    "        img1 = oriimg.convert('RGB')\n",
    "        img2 = img1.resize((int(IMG_SIZ), int(IMG_SIZ)), Image.LANCZOS)  # resize image\n",
    "        gray = cv2.cvtColor(np.float32(img2), cv2.COLOR_RGB2GRAY)  # rgb to grayscale\n",
    "        img_b = cv2.GaussianBlur(gray, (3, 3), 0)  # Gaussian blur\n",
    "        img3 = auto_canny(np.uint8(img_b), sigma=0.33)  # Canny edge detector\n",
    "        cv2.imwrite(path + '/' + foldername + '/' + filename, img3)  # replace original figure\n",
    "    print(foldername)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our first baseline implementation of a CNN\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "# Randomly flip, rotate, and zoom examples before training\n",
    "augment_layers = Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\",\n",
    "        input_shape=(imgh, imgw, 3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "model = Sequential([\n",
    "    augment_layers,\n",
    "    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(imgh, imgw, 3)),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A script for data augmentation and formatting the data directory\n",
    "# for use with the following data loaders\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.3)  #\n",
    "for foldername in os.listdir('data/train/'):  # read original images in the path:  data/train/Hammer,\n",
    "    # data/train/Screw Driver and data/train/Wrench\n",
    "    for file_name in os.listdir('data/train' + '/' + foldername):\n",
    "        img = load_img('data/train' + '/' + foldername + '/' + file_name)\n",
    "        x = img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape)\n",
    "\n",
    "        i = 1\n",
    "        # j = 1\n",
    "        for batch in datagen.flow(x,\n",
    "                                  batch_size=32,\n",
    "                                  save_to_dir='data/train_b' + '/' + foldername,  # save new images to the path: data/train_b/Hammer\n",
    "                                  save_prefix=foldername + '_b' + str(i),\n",
    "                                  save_format='jpg'):\n",
    "            i += 1\n",
    "            if i > 20:  # stop if 20 images are generated from 1 original image\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A different method we used for loading data that includes the preprocessing\n",
    "# Requires a slightly different directory structure\n",
    "\n",
    "batch_size = 32\n",
    "imgh = 224 # height\n",
    "imgw = 224 # width\n",
    "\n",
    "# Instances of a Keras data generator class\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,             # rescale the image\n",
    "    rotation_range=20,            # random rotate up to 20 degrees\n",
    "    brightness_range=[0.2, 1.0],  # random brightness shift\n",
    "    horizontal_flip=True,         # horzontally flip\n",
    "    vertical_flip=True,           # vertically flip\n",
    "    zoom_range=0.2)               # random zoom\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    ")\n",
    "\n",
    "# Loading in data using the generators\n",
    "train_ds = train_datagen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(imgh, imgh),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "val_ds = valid_datagen.flow_from_directory(\n",
    "    'data/validation',\n",
    "    target_size=(imgh, imgh),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One example of a different model structure that we experimented with\n",
    "def getModel(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), padding=\"same\", activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = getModel(train_ds.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to compile the model\n",
    "# We manually set learning rate to enable experimenting with different values\n",
    "# We used both categorical and sparse categorical cross-entropy loss\n",
    "# Sparse returns classes instead of probability, less computation saves training time\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "#     loss=\"categorical_crossentropy\",\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the callbacks for training\n",
    "# EarlyStopping monitors validation loss and will stop the model if it does not\n",
    "#   continue to decrease for <patience> epochs. Set more or less depending on expected \n",
    "#   number of epochs. Prevents overfitting from occuring.\n",
    "# Checkpointing to save the model weights in case of an issue, to enable training in \n",
    "#    multiple sessions, and loading to test\n",
    "# Write logs for debugging\n",
    "\n",
    "patience = 30\n",
    "my_callbacks = [\n",
    "    EarlyStopping(patience=patience),\n",
    "    ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    TensorBoard(log_dir='./logs'),\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "epochs = 400\n",
    "history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator, shuffle=True, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our implementation of a classifier using the VGG16 model for feature extraction\n",
    "\n",
    "# load pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, pooling=None, input_shape=(224, 224, 3),\n",
    "                   classes=3)\n",
    "\n",
    "# freeze pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add our dense layer to new model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# new model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# optimizer, learning rate and compile\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# callbacks, save the model with highest accuracy\n",
    "tbCallBack = TensorBoard(log_dir='./logs/',\n",
    "                         histogram_freq=0,\n",
    "                         batch_size=16,\n",
    "                         write_graph=True,\n",
    "                         write_grads=True,\n",
    "                         write_images=True,\n",
    "                         embeddings_freq=0,\n",
    "                         embeddings_layer_names=None,\n",
    "                         embeddings_metadata=None)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='vgg16_edge.h5', monitor='val_accuracy', mode='auto', save_best_only='True')\n",
    "\n",
    "# train new model\n",
    "history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=150,\n",
    "    callbacks=[tbCallBack, checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After traing a model and saving the metrics history, we plot \n",
    "# training and validation accuracy and loss\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs) # must be adjusted manually if training stops early\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After we have trained a model and saved it to disk, we load it \n",
    "#    and test it against our test set\n",
    "\n",
    "model_path = \"final.h5\"\n",
    "# read model from file\n",
    "trained_model = load_model(model_path)\n",
    "\n",
    "# Load in testing images from directory\n",
    "# Resize only, no preprocessing done\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'data/test',\n",
    "    target_size=(imgh, imgh),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=\"sparse\",\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# displaying the number of test images\n",
    "filenames = test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "print(nb_samples)\n",
    "\n",
    "# make predictions on the test images\n",
    "# returned array is of size (3, number of examples)\n",
    "#    where each example has 3 float values representing\n",
    "#    their probability of being in the corresponding class\n",
    "Y_pred = trained_model.predict(test_generator)\n",
    "\n",
    "# create a vector of class predictions in range {0, 1, 2}\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "# display a confusion matrix of our test results\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['hammer', 'screwdriver', 'wrench']\n",
    "\n",
    "# display a classification report \n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "# calculate the ROC and AUC metrics\n",
    "y_test = test_generator.classes\n",
    "macro_roc_auc_ovo = sk.metrics.roc_auc_score(y_test, Y_pred, multi_class=\"ovo\", average=\"macro\")\n",
    "weighted_roc_auc_ovo = sk.metrics.roc_auc_score(y_test, Y_pred, multi_class=\"ovo\", average=\"weighted\")\n",
    "macro_roc_auc_ovr = sk.metrics.roc_auc_score(y_test, Y_pred, multi_class=\"ovr\", average=\"macro\")\n",
    "weighted_roc_auc_ovr = sk.metrics.roc_auc_score(y_test, Y_pred, multi_class=\"ovr\", average=\"weighted\")\n",
    "print(\"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "      \"(weighted by prevalence)\"\n",
    "      .format(macro_roc_auc_ovo, weighted_roc_auc_ovo))\n",
    "print(\"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "      \"(weighted by prevalence)\"\n",
    "      .format(macro_roc_auc_ovr, weighted_roc_auc_ovr))\n",
    "\n",
    "# For the three class probabilities for each example,\n",
    "#    set the index with the highest probability to 1,\n",
    "#    the rest set to 0\n",
    "tmp = []\n",
    "for i in y_test:\n",
    "    if i == 0: tmp.append([1, 0, 0])\n",
    "    elif i == 1: tmp.append([0, 1, 0])        \n",
    "    elif i == 2: tmp.append([0, 0, 1])\n",
    "y_test = np.array(tmp)\n",
    "\n",
    "# compute data for ROC curve plot\n",
    "n_classes = 3\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], Y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), Y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
